{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fbb2151b855b8b",
   "metadata": {},
   "source": [
    "# Discovering Causal Relationships through Gradient Learning\n",
    "\n",
    "Imagine you've collected data on student study hours, sleep patterns, and exam scores. You notice correlations between these variables, but correlation doesn't imply causation which is a fundamental challenge in data analysis. Does more studying cause better exam performance? Does sleep quality affect study efficiency? Or do other factors drive these relationships?\n",
    "\n",
    "Unlike standard machine learning that focuses on prediction, causal inference seeks to understand the underlying mechanisms: what causes what.\n",
    "\n",
    "Traditionally, establishing causality required controlled experiments where we manipulate variables and observe outcomes. But what if experiments are impossible, unethical, or too expensive? Can we infer causality from observational data alone?\n",
    "\n",
    "Approaches differ from constraint-based methods (like the PC algorithm) that test conditional independence, and score-based methods that search for graph structures optimizing certain criteria. Both approaches face a fundamental hurdle: learning a Directed Acyclic Graph (DAG) is a combinatorial optimization problem with a super-exponential search space ie. there are $2^(n^2)$ possible edge configurations for n variables.\n",
    "\n",
    "# The Challenge\n",
    "## Learning Dags from data\n",
    "Simplistically at it's core the problem is about finding a Directed Acyclic Graph (DAG) from a data generating process. A node would represent a variable, and the edge would represent the relationship. The edge is weighted to represent the strength of the relationship.\n",
    "\n",
    "## Traditional Approaches and Their Limitations\n",
    "Previous methods for causal discovery generally fall into two categories:\n",
    "1. Constraint-Based Methods (like PC and FCI algorithms):\n",
    "\n",
    "- Test conditional independence between variables\n",
    "- Build a graph consistent with these independence relationships\n",
    "- **Advantages**: Require fewer assumptions about the data distribution\n",
    "- **Limitations**: Sensitive to errors in independence tests, especially with limited data\n",
    "\n",
    "2. Score-Based Methods (like GES and various Bayesian approaches):\n",
    "\n",
    "- Define a score function that measures how well a graph explains the data\n",
    "- Search through the space of possible graphs to maximize this score\n",
    "- **Advantages**: Can incorporate prior knowledge and handle uncertainty\n",
    "- **Limitations**: The search space grows super-exponentially with the number of variables\n",
    "\n",
    "Both of these class of approaches as discussed by the paper struggle with one thing: *ensuring dag acyclicity*. The space of all possible graph is large but only a fraction are acyclic.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from utils import timing\n",
    "\n",
    "\n",
    "def generate_random_dag(d, s0):\n",
    "    \"\"\"Generate a random DAG with d nodes and s0 expected edges.\"\"\"\n",
    "    # Create a random lower triangular matrix with random weights\n",
    "    A = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(i):\n",
    "            if np.random.rand() < s0/(d-1):\n",
    "                A[j, i] = np.random.uniform(0.5, 2.0) * np.random.choice([-1, 1])\n",
    "\n",
    "    # Randomly permute the nodes to get a random DAG\n",
    "    P = np.random.permutation(np.eye(d))\n",
    "    A = P.T @ A @ P\n",
    "\n",
    "    return A\n",
    "\n",
    "def generate_sem_data(W, n, noise_scale=1.0):\n",
    "    \"\"\"Generate data from a linear SEM X = XW + Z.\"\"\"\n",
    "    d = W.shape[0]\n",
    "    I = np.eye(d)\n",
    "    Z = np.random.normal(0, noise_scale, size=(n, d))\n",
    "\n",
    "    # For NOTEARS, we need W where W[i,j] means j→i\n",
    "    W_notears = W.T\n",
    "\n",
    "    # Use matrix form: X = (I-W')^(-1)Z  (where W' is in NOTEARS convention)\n",
    "    X = Z @ np.linalg.inv(I - W_notears.T)\n",
    "\n",
    "    return X, W_notears"
   ],
   "id": "118161afb88eb70e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.random.seed(42)\n",
    "nodes, edges = 5, 2\n",
    "samples = 1000\n",
    "A = generate_random_dag(nodes, edges)\n",
    "X, W_true = generate_sem_data(A, 1000)\n",
    "A"
   ],
   "id": "9c278bf8e056c63d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import visualize_dag\n",
    "\n",
    "visualize_dag(W_true)"
   ],
   "id": "ef652926005f3483"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following dag represents causal relationships where the nodes are the variables we're exploring and the arrows indicate the direction to where the variable directly causes or effects the other. The edge weights represent the strength of the causal effect. A positive increase in cause increase in effect whilst a negative means increase in cause decrease in effect.\n",
    "\n",
    "Relationships in this toy example:\n",
    "\n",
    "- X3 has a negative effect (-1.93) on X1\n",
    "- X3 has a positive effect (1.95) on X0\n",
    "- X0 influences X2 with a negative effect (-1.99)\n",
    "- X1 has a small negative effect (-0.65) on X2\n",
    "- X4 appears isolated (no edges connecting to it)\n",
    "\n",
    "In layman's terms this could mean\n",
    "- X3 could be considered a \"common cause\" for X2, X3, and X0\n",
    "- X4 is independent of the other variables (a confounding variable that wasn't detected or has no relationship)\n",
    "\n",
    "This scenario is ideal for this algorithm to work because:\n",
    "- It has no cycles\n",
    "- Weighted edges representing the strength of causal effects\n",
    "- A mix of relationships (some variables with multiple parents/children, some isolated)"
   ],
   "id": "f0ff56889111602c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Benchmark\n",
    "\n",
    "Before diving into the implementation, it's valuable to understand how NOTEARS compares to traditional causal discovery approaches. This comparison helps illustrate why gradient-based methods represent such a significant advancement in the field.\n"
   ],
   "id": "b438e4866f1c60c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causallearn.search.ScoreBased.GES import ges\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "\n",
    "from utils import plot_dag_comparison\n",
    "\n",
    "@timing\n",
    "def run_ges(X):\n",
    "    cg = ges(X, score_func=\"local_score_BIC\")\n",
    "    G = cg['G'].graph\n",
    "    # Convert to adjacency matrix\n",
    "    return nx.to_numpy_array(nx.DiGraph(G))\n",
    "\n",
    "@timing\n",
    "def run_pc(X):\n",
    "    record = pc(X, score_func=\"local_score_BIC\")\n",
    "    G = record.G.graph\n",
    "    # Convert to adjacency matrix\n",
    "    return nx.to_numpy_array(nx.DiGraph(G))\n",
    "\n",
    "W_est_ges, time_taken_ges = run_pc(X)"
   ],
   "id": "e222152e6c9c2ddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_dag_comparison(W_true, W_est_ges)",
   "id": "8d9e6cdcc0450775"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What PC Got Right\n",
    "\n",
    "1. **Correct Edge Detection**: PC successfully identified several true causal relationships:\n",
    "\n",
    "- The connection between nodes 3 and 0 (though the direction is uncertain)\n",
    "- The relationship involving node 2 as a hub/sink\n",
    "- *Some* of the connections to node 1\n",
    "\n",
    "2. **Sparsity**: PC maintained a reasonable level of sparsity, avoiding the creation of an overly dense graph\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Missing edges**\n",
    "- Teh algorithm missed the edge from 3→1 (weight of -1.93)\n",
    "2. **Edge Direction**\n",
    "- This is a fundamental limitation of methods like PC and GES\n",
    "- PC can only orient edges when there are clear v-structures (X→Z←Y) or other identifiable patterns\n",
    "- Many edges remain unoriented or may be incorrectly oriented due to insufficient statistical power\n",
    "3. **Strength of Casual Realtionship**\n",
    "- PC performs conditional independence tests that return binary results (independent/dependent)\n",
    "- It builds the graph by deciding whether edges exist or not, without estimating effect strengths\n",
    "\n",
    "### Why these differences?\n",
    "These differences happen for a number of reasons:\n",
    "1. **Statistical Testing Limitations:**\n",
    "\n",
    "- PC relies on conditional independence tests, which can fail with:\n",
    "    - Limited sample sizes\n",
    "    - Weak relationships (small effect sizes)\n",
    "    - Non-linear relationships (even mild ones)\n",
    "2. **Multiple testing**\n",
    "- PC performs many statistical tests, increasing the chance of false positives\n",
    "\n",
    "Before explaining and implementing the no tears algorithm lets run a few scenarios to highlight the problems with the PC algorithm further. I'm going to import the evaluate_reconstruction function from my utils module which will calculate several important plots and metrics.\n",
    "\n",
    "#### Performance Metrics\n",
    "From the confusion matrix we can get\n",
    "- TP - True Positive: Correctly identified edges that actually exist\n",
    "- FP - False Positive: Incorrectly identified edges that don't actually exist\n",
    "- FN - False Negative: Missed edges that actually exist\n",
    "- TN - True Negative: Correctly identified absence of edges\n",
    "\n",
    "From these results we can calculate the:\n",
    "- Precision: Is the fraction of correct edges $P = \\frac{tp}{tp+fp}$\n",
    "- Recall: Is the fraction of relevant edges that were retrieved $R = \\frac{tp}{tp+fn}$\n",
    "- F1 score: The harmonic mean between precision and recall $F1 = 2 \\cdot \\frac{P \\cdot R}{P + R}$\n",
    "\n",
    "We can also compute the Structural Hamming Distance (SHD) which is a standard distance to compare graphs by their adjacency matrix.\n",
    "\n",
    "#### Performance Plots\n",
    "##### Left Plot: True DAG Structure (Binary Adjacency Matrix)\n",
    "- Dark blue squares: Indicate true causal relationships (edges exist)\n",
    "- White squares: No causal relationship exists\n",
    "- Reading: If there's a dark square at position (i,j), it means variable j causes variable i\n",
    "\n",
    "##### Middle Plot: Estimated DAG Structure\n",
    "- Shows what the PC algorithm discovered\n",
    "- Dark blue squares: Edges the PC algorithm detected\n",
    "- White squares: No relationship detected by PC\n",
    "\n",
    "#### Right Plot: Edge Recovery Analysis\n",
    "This is a confusion matrix showing the algorithm's performance:\n",
    "\n",
    "- Blue (TP - True Positive)\n",
    "- Green (FP - False Positive)\n",
    "- Red (FN - False Negative)\n",
    "- White (TN - True Negative)\n"
   ],
   "id": "2cc4c30459f701c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import evaluate_reconstruction\n",
    "\n",
    "def analyze_sample_size_effects():\n",
    "    sample_sizes = [100, 500, 1000, 2000]\n",
    "    results = []\n",
    "\n",
    "    for n in sample_sizes:\n",
    "        X_subset = X[:n, :]  # Use first n samples\n",
    "        W_pc, _ = run_pc(X_subset)\n",
    "        metrics = evaluate_reconstruction(W_true, W_pc)\n",
    "        results.append({\n",
    "            'n_samples': n,\n",
    "            'f1': metrics['f1']\n",
    "        })\n",
    "\n",
    "    return results\n",
    "analyze_sample_size_effects()"
   ],
   "id": "b6f7b11d4a8781d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The PC algorithm faired moderately well on this graph structure and varying data points. The f1 metrics ranged between 0.5 and 0.6\n",
    "However it missed important edges, the failure to detect 3→1 could be crucial in real applications\n",
    "There are also a number of important false discoveries and the green squares show PC is adding edges that don't exist. These could be potentially misleading."
   ],
   "id": "61f18b9674dec166"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NOTEARS\n",
    "NOTEARS (NonParametric Estimation of Acyclic diREcted graphS) introduced a remarkably elegant solution to reduce the search space: reformulate the acyclicity constraint as a differentiable function of the weight matrix W:\n",
    "$$\n",
    "h(W) = tr(e^{(W \\cdot W)}) - d = 0\n",
    "$$\n",
    "where:\n",
    "- tr() is the trace operator (sum of diagonal elements)\n",
    "- $e^{(W \\cdot W)}$ is the matrix exponential of the Hadamard element-wise product\n",
    "- d is the number of variables"
   ],
   "id": "f2b6c71f5327c59d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import scipy.optimize as sopt\n",
    "from functools import partial\n",
    "from jax import jit, value_and_grad\n",
    "\n",
    "\n",
    "@jit\n",
    "def h_acyclic(W):\n",
    "    \"\"\"\n",
    "    Calculate the acyclicity constraint value.\n",
    "    :param W: the weight data matrix W\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    d = W.shape[0]\n",
    "    E = jax.scipy.linalg.expm(W * W)\n",
    "    return jnp.trace(E) - d\n",
    "\n",
    "@jit\n",
    "def l2_loss(X, W):\n",
    "    \"\"\"\n",
    "    Calculate L2 loss between data X and model X@W.\n",
    "    :param X: the input matrix\n",
    "    :param W: the weight matrix\n",
    "    :return: the l2 loss between X@W\n",
    "    \"\"\"\n",
    "    M = X @ W\n",
    "    R = X - M\n",
    "    return 0.5 / X.shape[0] * jnp.sum(R ** 2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def _adj(w, d):\n",
    "    \"\"\"\n",
    "    Convert doubled variables [w_pos, w_neg] to weight matrix W = w_pos - w_neg.\n",
    "\n",
    "    NOTEARS uses a trick to handle both positive and negative edge weights while\n",
    "    maintaining non-negativity constraints during optimization. Each edge weight\n",
    "    W[i,j] is represented as w_pos[i,j] - w_neg[i,j] where both w_pos and w_neg\n",
    "    are constrained to be non-negative.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : jax.numpy.ndarray\n",
    "        Flattened weight vector of length 2*d^2, containing [w_pos.flatten(), w_neg.flatten()]\n",
    "    d : int\n",
    "        Number of variables (nodes) in the DAG. Must be static for JIT compilation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jax.numpy.ndarray\n",
    "        Weight matrix W of shape (d, d) where W[i,j] represents the causal effect\n",
    "        of variable j on variable i\n",
    "    \"\"\"\n",
    "    d_squared = d * d\n",
    "    w_pos = w[:d_squared].reshape((d, d))\n",
    "    w_neg = w[d_squared:].reshape((d, d))\n",
    "    return w_pos - w_neg\n",
    "\n",
    "@partial(jit, static_argnums=(2,))\n",
    "def augmented_lagrangian(w, X, d, alpha, rho, lambda1):\n",
    "    \"\"\"\n",
    "    Compute the augmented Lagrangian objective.\n",
    "    :param w:\n",
    "    :param X:\n",
    "    :param d:\n",
    "    :param alpha:\n",
    "    :param rho:\n",
    "    :param lambda1:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    W = _adj(w, d)\n",
    "    loss = l2_loss(X, W)\n",
    "    h = h_acyclic(W)\n",
    "    return loss + 0.5 * rho * h * h + alpha * h + lambda1 * jnp.sum(w)\n",
    "\n",
    "# Create compiled value_and_grad function\n",
    "aug_lagrangian_with_grad = value_and_grad(augmented_lagrangian, argnums=0)\n",
    "aug_lagrangian_with_grad = partial(jit, static_argnums=(2,))(aug_lagrangian_with_grad)"
   ],
   "id": "e45d09e44b76bb9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_dag_bounds(d):\n",
    "    \"\"\"\n",
    "    Create bounds for the optimization variables in the doubled-variable formulation.\n",
    "\n",
    "    In NOTEARS, each weight W[i,j] is represented as w_pos[i,j] - w_neg[i,j] where\n",
    "    both w_pos and w_neg are non-negative. This function creates bounds for the\n",
    "    flattened vector [w_pos.flatten(), w_neg.flatten()].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : int\n",
    "        Number of variables (nodes) in the DAG\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuple\n",
    "        List of (min, max) bounds for each optimization variable.\n",
    "        Length is 2*d^2. Diagonal elements are bounded to (0,0) to prevent\n",
    "        self-loops, off-diagonal elements are bounded to (0, None).\n",
    "    \"\"\"\n",
    "    bounds = []\n",
    "    for k in range(2):  # For w_pos and w_neg\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                if i == j:\n",
    "                    bounds.append((0, 0))  # No self-loops\n",
    "                else:\n",
    "                    bounds.append((0, None))  # Non-negative weights\n",
    "    return bounds\n",
    "\n",
    "def create_scipy_wrapper(w, X, d, alpha, rho, lambda1):\n",
    "    \"\"\"\n",
    "    Create a wrapper function for scipy optimizer that converts between JAX and NumPy.\n",
    "\n",
    "    SciPy's optimizers expect NumPy arrays and return NumPy arrays, while our\n",
    "    JAX implementation uses JAX arrays. This wrapper handles the conversion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : jax.numpy.ndarray\n",
    "        Current weight vector (used for function signature, not actual computation)\n",
    "    X : jax.numpy.ndarray\n",
    "        Data matrix of shape (n_samples, n_variables)\n",
    "    d : int\n",
    "        Number of variables (nodes) in the DAG\n",
    "    alpha : float\n",
    "        Lagrange multiplier for the acyclicity constraint\n",
    "    rho : float\n",
    "        Penalty parameter for the augmented Lagrangian\n",
    "    lambda1 : float\n",
    "        L1 regularization strength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    callable\n",
    "        Function that takes NumPy array and returns (objective_value, gradient)\n",
    "        suitable for SciPy's minimize function with jac=True\n",
    "    \"\"\"\n",
    "    def scipy_obj_and_grad(w_np):\n",
    "        w_jax = jnp.array(w_np)\n",
    "        obj, grad = aug_lagrangian_with_grad(w_jax, X, d, alpha, rho, lambda1)\n",
    "        return float(obj), np.array(grad)\n",
    "    return scipy_obj_and_grad\n",
    "\n",
    "def optimize_weights(w_est, X, d, alpha, rho, lambda1, bounds):\n",
    "    \"\"\"\n",
    "    Perform one step of L-BFGS-B optimization for the augmented Lagrangian.\n",
    "\n",
    "    This function wraps SciPy's L-BFGS-B optimizer to solve the constrained\n",
    "    optimization problem in NOTEARS using the augmented Lagrangian method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w_est : jax.numpy.ndarray\n",
    "        Current estimate of the weight vector (length 2*d^2)\n",
    "    X : jax.numpy.ndarray\n",
    "        Data matrix of shape (n_samples, n_variables)\n",
    "    d : int\n",
    "        Number of variables (nodes) in the DAG\n",
    "    alpha : float\n",
    "        Lagrange multiplier for the acyclicity constraint\n",
    "    rho : float\n",
    "        Penalty parameter for the augmented Lagrangian\n",
    "    lambda1 : float\n",
    "        L1 regularization strength\n",
    "    bounds : list of tuple\n",
    "        Bounds for each optimization variable from create_dag_bounds()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jax.numpy.ndarray\n",
    "        Optimized weight vector of length 2*d^2\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses L-BFGS-B which is a quasi-Newton method that handles box constraints\n",
    "    efficiently. The method is well-suited for the smooth optimization problems\n",
    "    arising in the augmented Lagrangian formulation.\n",
    "    \"\"\"\n",
    "    # Convert to numpy for scipy\n",
    "    w_np = np.array(w_est)\n",
    "\n",
    "    # Create the objective function wrapper\n",
    "    obj_func = create_scipy_wrapper(w_est, X, d, alpha, rho, lambda1)\n",
    "\n",
    "    # Run L-BFGS-B optimization\n",
    "    result = sopt.minimize(\n",
    "        obj_func, w_np, method='L-BFGS-B',\n",
    "        jac=True, bounds=bounds\n",
    "    )\n",
    "\n",
    "    # Return JAX array\n",
    "    return jnp.array(result.x)\n",
    "\n",
    "def threshold_weights(W, threshold):\n",
    "    \"\"\"\n",
    "    Apply thresholding to remove small edges from the estimated DAG.\n",
    "\n",
    "    Sets edge weights with absolute value below the threshold to exactly zero.\n",
    "    This is a common post-processing step in causal discovery to produce\n",
    "    sparse graphs and remove weak, potentially spurious connections.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : jax.numpy.ndarray\n",
    "        Weight matrix of shape (d, d) representing the DAG\n",
    "    threshold : float\n",
    "        Minimum absolute weight value to retain. Edges with |weight| < threshold\n",
    "        are set to zero\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jax.numpy.ndarray\n",
    "        Thresholded weight matrix with the same shape as W\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> W = jnp.array([[0, 0.8, 0.02], [0, 0, 0.5], [0, 0, 0]])\n",
    "    >>> threshold_weights(W, 0.1)\n",
    "    Array([[0. , 0.8, 0. ],\n",
    "           [0. , 0. , 0.5],\n",
    "           [0. , 0. , 0. ]], dtype=float32)\n",
    "    \"\"\"\n",
    "    return jnp.where(jnp.abs(W) < threshold, 0, W)"
   ],
   "id": "44474d75e225bd00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@timing\n",
    "def notears_linear(X, lambda1=0.1, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Learn a DAG from data using the NOTEARS algorithm.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): [n, d] data matrix\n",
    "        lambda1 (float): L1 regularization parameter\n",
    "        max_iter (int): Maximum number of dual ascent steps\n",
    "        h_tol (float): Exit if |h(W)| <= h_tol\n",
    "        rho_max (float): Exit if rho >= rho_max\n",
    "        w_threshold (float): Remove edges with |weight| < threshold\n",
    "\n",
    "    Returns:\n",
    "        W_est (ndarray): [d, d] estimated DAG\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    n, d = X.shape\n",
    "    X = X - jnp.mean(X, axis=0)  # Center the data\n",
    "\n",
    "    # Initialize parameters\n",
    "    w_est = jnp.zeros(2 * d * d)  # [w_pos, w_neg]\n",
    "    rho, alpha, h = 1.0, 0.0, jnp.inf\n",
    "\n",
    "    # Create bounds for optimization\n",
    "    bounds = create_dag_bounds(d)\n",
    "\n",
    "    # Augmented Lagrangian optimization\n",
    "    for i in range(max_iter):\n",
    "        # Inner optimization\n",
    "        w_new = None\n",
    "        inner_converged = False\n",
    "\n",
    "        while rho < rho_max and not inner_converged:\n",
    "            # Optimize weights\n",
    "            w_new = optimize_weights(w_est, X, d, alpha, rho, lambda1, bounds)\n",
    "\n",
    "            # Check acyclicity\n",
    "            W_new = _adj(w_new, d)\n",
    "            h_new = h_acyclic(W_new)\n",
    "\n",
    "            # Update penalty parameter if needed\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                inner_converged = True\n",
    "\n",
    "        # Update estimates\n",
    "        w_est = w_new\n",
    "        h = h_acyclic(_adj(w_est, d))\n",
    "        alpha += rho * h\n",
    "\n",
    "        # Log progress\n",
    "        print(f\"Iteration {i}: h={h:.6e}, rho={rho:.2e}\")\n",
    "\n",
    "        # Check convergence\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "\n",
    "    # Final processing\n",
    "    W_est = _adj(w_est, d)\n",
    "\n",
    "    # Thresholding\n",
    "    W_est = jnp.where(jnp.abs(W_est) < w_threshold, 0, W_est)\n",
    "\n",
    "    print(f\"Final h(W): {h_acyclic(W_est):.6e}\")\n",
    "\n",
    "    # Transpose to get standard adjacency matrix where W[i,j]≠0 means i→j\n",
    "    W_est = W_est.T\n",
    "\n",
    "    return W_est\n",
    "\n"
   ],
   "id": "ca42a902df32dd1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lambda1=0.05\n",
    "loss_type='l2'\n",
    "max_iter=100\n",
    "h_tol=1e-8\n",
    "rho_max=1e+16\n",
    "w_threshold=0.2\n",
    "estimated_A, time_taken_jax = notears_linear(X, lambda1, max_iter, h_tol, rho_max, w_threshold)\n",
    "plot_dag_comparison(W_true, estimated_A)"
   ],
   "id": "7c728b90ed4ffdee"
  },
  {
   "cell_type": "code",
   "id": "b1ff23fca5ba3f2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T08:56:25.958284Z",
     "start_time": "2025-05-26T08:56:25.781539Z"
    }
   },
   "source": "evaluate_reconstruction(W_true, estimated_A)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': np.float64(1.0),\n",
       " 'recall': np.float64(1.0),\n",
       " 'f1': np.float64(1.0),\n",
       " 'true_edges': np.int64(4),\n",
       " 'est_edges': np.int64(4),\n",
       " 'true_positive': np.int64(4),\n",
       " 'false_positive': np.int64(0),\n",
       " 'false_negative': np.int64(0),\n",
       " 'true_negative': np.int64(21),\n",
       " 'shd': np.float64(0.0),\n",
       " 'additions': np.int64(0),\n",
       " 'deletions': np.int64(0),\n",
       " 'reversals': np.float64(0.0)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T08:56:25.966037Z",
     "start_time": "2025-05-26T08:56:25.964684Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "80165b5a8e37606e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
